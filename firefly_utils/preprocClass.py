import numpy as np
import os, sys, re
from data_handler import *
from scipy.io import loadmat
from copy import deepcopy
import bisect
from scipy.interpolate import interp1d
from behav_class import emptyStruct
import operator
from extract_presence_rate import extract_presecnce_rate_Uprobe, extract_presecnce_rate

class fireFly_dataPreproc(data_handler):
    """
    This containers will load the math file containing the task variables and the <br>
    counts. It will add specific preprocessing method that will simplify the re-binning and<br>
    formatting of the data.
    """

    def __init__(self, filepath, flyON_dur=0.3, pre_trial_dur=0.2, post_trial_dur=0.2,
                 extract_presence_rate=False,user_paths=None,
                 lfp_beta=None,lfp_alpha=None,lfp_theta=None):

        re.findall('m\d+s\d+', filepath)
        session = re.findall('m\d+s\d+', filepath)[0]

        # keys in the mat file generated by the preprocessing script of  K.
        behav_stat_key = 'behv_stats'
        spike_key = 'units'
        behav_dat_key = 'trials_behv'
        lfp_key = 'lfps'

        use_left_eye = ['53s48']

        if session in use_left_eye:
            use_eye = 'left'
        else:
            use_eye = 'right'

        extract_any = False
        if not lfp_beta is None:
            dirname = os.path.dirname(filepath)
            lfp_beta = loadmat(os.path.join(dirname,'lfp_beta_%s.mat'%session))['lfp_beta']
            path_lfp = os.path.join(dirname, 'lfp_beta_%s.mat' % session)
            extract_any = True

        if not lfp_alpha is None:
            dirname = os.path.dirname(filepath)
            lfp_alpha = loadmat(os.path.join(dirname,'lfp_alpha_%s.mat'%session))['lfp_alpha']
            path_lfp = os.path.join(dirname, 'lfp_alpha_%s.mat' % session)
            extract_any = True

        if not lfp_theta is None:
            dirname = os.path.dirname(filepath)
            lfp_theta = loadmat(os.path.join(dirname,'lfp_theta_%s.mat'%session))['lfp_theta']
            path_lfp = os.path.join(dirname,'lfp_theta_%s.mat'%session)
            extract_any = True

        if not extract_any:
            path_lfp = ''
            lfp_key = None

        # presence rate params
        occupancy_bin_sec = 60  # at least one spike per min
        occupancy_rate_th = 0.1  # hz

        linearprobe_sampling_fq = 20000
        utah_array_sampling_fq = 30000

        dat = loadmat(filepath)

        super(fireFly_dataPreproc, self).__init__(dat, behav_dat_key, spike_key, lfp_key, behav_stat_key,
                                                  pre_trial_dur=pre_trial_dur,
                                                  post_trial_dur=post_trial_dur,
                                                  lfp_beta=lfp_beta, lfp_alpha=lfp_alpha, lfp_theta=lfp_theta,
                                                  extract_lfp_phase=True,
                                                  use_eye=use_eye, fhLFP=path_lfp, extract_fly_and_monkey_xy=True,
                                                  flyON_dur=flyON_dur)

        # if not lfp_beta is None:
        #     self.lfp.lfp_beta_phase = self.lfp.extract_phase_from_band(self.lfp.lfp_beta, np.ones(self.lfp.n_trials,dtype=bool),
        #                                           self.spikes.channel_id,self.spikes.brain_area)
        # if not lfp_alpha is None:
        #     self.lfp.lfp_alpha_phase = self.lfp.extract_phase_from_band(self.lfp.lfp_alpha, np.ones(self.lfp.n_trials,dtype=bool),
        #                                           self.spikes.channel_id,self.spikes.brain_area)
        # if not lfp_theta is None:
        #     self.lfp.lfp_theta_phase = self.lfp.extract_phase_from_band(self.lfp.lfp_theta, np.ones(self.lfp.n_trials,dtype=bool),
        #                                           self.spikes.channel_id,self.spikes.brain_area)


        self.set_filters('all', True)
        self.preProcessed = None
        
        cont_rate_filter = (self.spikes.cR < 0.2) | (self.spikes.unit_type == 'multiunit')
        
        isi_v_filter = self.spikes.isiV < 0.2
        
        if extract_presence_rate:
            occupancy_bin_sec = 60
            occupancy_rate_th = 0.1
            unit_info = {}
            unit_info['unit_type'] = self.spikes.unit_type
            unit_info['spike_width'] = self.spikes.spike_width
            unit_info['waveform'] = self.spikes.waveform
            unit_info['amplitude_wf'] = self.spikes.amplitude_wf
            unit_info['cluster_id'] = self.spikes.cluster_id
            unit_info['electrode_id'] = self.spikes.electrode_id
            unit_info['channel_id'] = self.spikes.channel_id
            unit_info['brain_area'] = self.spikes.brain_area
            unit_info['uQ'] = self.spikes.uQ
            unit_info['isiV'] = self.spikes.isiV
            unit_info['cR'] = self.spikes.cR
            unit_info['date_exp'] = self.date_exp
            if ('m72' in session) or ('m73' in session):
                presence_rate_filter = extract_presecnce_rate_Uprobe(occupancy_bin_sec,occupancy_rate_th, unit_info,session,
                                                             user_paths,linearprobe_sampling_fq,use_server=None)
            else:
                presence_rate_filter = extract_presecnce_rate(occupancy_bin_sec,occupancy_rate_th,unit_info,session,
                                                      user_paths,utah_array_sampling_fq,linearprobe_sampling_fq,use_server=None)
                
                
            presence_rate_filter = presence_rate_filter['presence_rate'] > 0.9
            
            self.unit_qual_filter = (cont_rate_filter) * (presence_rate_filter) * (isi_v_filter)
        else:
            self.unit_qual_filter = (cont_rate_filter) * (isi_v_filter)
        return

    def setInitialCond(self, condition='noMovement', init_event='t_flyON',
                       oper=operator.or_,abs=True,speedThPerc=95):
        condList = ['noMovement', 'maxSpeed']
        if  not condition in condList:
            raise ValueError('Condition "%s" is not coded for' % condition)

        if init_event == 't_flyON':
            ev_dict = {}
            for tr in self.behav.events.t_flyOFF.keys():
                ev_dict[tr] = self.behav.events.t_flyOFF[tr] - self.behav.flyON_dur
        else:
            try:
                ev_dict = self.behav.events.__dict__[init_event]
            except KeyError:
                raise KeyError('Event "%s" was not loaded'%init_event)

        if condition == 'noMovement':
            # filter for trial where velocity is null at the event
            for tr in self.behav.continuous.rad_vel.keys():
                ts = self.behav.time_stamps[tr]
                if abs:
                    vel = np.abs(self.behav.continuous.rad_vel[tr])
                    angvel = np.abs(self.behav.continuous.ang_vel[tr])
                else:
                    vel = self.behav.continuous.rad_vel[tr]
                    angvel = self.behav.continuous.ang_vel[tr]
                iidx = bisect.bisect_left(ts, ev_dict[tr])
                # this params are used for start and stop detection
                if oper((vel[iidx] > 5), (angvel[iidx] > 3)):
                    self.filter[tr] = False
                elif self.behav.events.t_move[tr] < 0:
                    xxx = 1

        if condition == 'maxSpeed':
            mxSpeed = np.nanpercentile(np.hstack(list(self.behav.continuous.rad_vel.values())),speedThPerc)
            print('SPEED THRRESHOLD: ',mxSpeed)
            # filter for trial where velocity is null at the event
            for tr in self.behav.continuous.rad_vel.keys():
                ts = self.behav.time_stamps[tr]
                vel = self.behav.continuous.rad_vel[tr]
                angvel = self.behav.continuous.ang_vel[tr]
                iidx = bisect.bisect_left(ts, ev_dict[tr])
                if oper((vel[iidx] < mxSpeed), (np.abs(angvel[iidx]) > 10)):
                    self.filter[tr] = False


        print('set filter for initial condition, trial matching:',self.filter.sum())

    def preProcPGPFA(self, binMs=20, init_event='t_flyON', final_event='t_stop', printEndString=True, smooth=False,
                     filt_window=None, preTrialMs=0, postTrialMs=0):

        assert(preTrialMs/1000. <= self.behav.pre_trial_dur)
        assert (postTrialMs/1000. <= self.behav.post_trial_dur)



        # get initial event dict
        if init_event == 't_flyON':
            ev0_dict = {}
            for tr in self.behav.events.t_flyOFF.keys():
                ev0_dict[tr] = self.behav.events.t_flyOFF[tr] - self.behav.flyON_dur

            ev0 = dict_to_vec(ev0_dict)
        else:
            try:
                ev0_dict = self.behav.events.__dict__[init_event]
            except KeyError:
                raise KeyError('Event "%s" was not loaded'%init_event)

        # get final event dict
        try:
            ev1_dict = self.behav.events.__dict__[final_event]
            # if final_event == 't_reward':
            #     ev_tstop = self.behav.events.t_stop
        except KeyError:
            raise KeyError('Event "%s" was not loaded' % final_event)

        ev1 = dict_to_vec(ev1_dict)


        for tr in self.behav.events.t_flyOFF.keys():
            ts0 = self.behav.time_stamps[tr][0]
            ts1 = self.behav.time_stamps[tr][-1]
            if ts0 > ev0_dict[tr] - preTrialMs/1000:
                self.filter[tr] = False
            else:
                ev0_dict[tr] = ev0_dict[tr] - preTrialMs / 1000
            if (ts1 < ev1_dict[tr] + postTrialMs/1000):# ~np.isnan(ts1) &
                self.filter[tr] = False

            # elif np.isnan(ts1):
            #     if final_event != 't_reward':
            #         self.filter[tr] = False
            #
            #     else:
            #         ev1_dict[tr] = ev_tstop[tr] + 200 + postTrialMs / 1000
            else:

                ev1_dict[tr] = ev1_dict[tr] + postTrialMs / 1000

        tr_sel = np.arange(self.behav.n_trials,dtype=int)[self.filter]

        bin_ts = self.time_stamps_rebin(binwidth_ms=binMs,t0_vec=ev0_dict)
        if not smooth:
            bin_list = self.spikes.bin_spikes(bin_ts, t_start=ev0_dict, t_stop=ev1_dict, select=self.filter,cutFirstLastTP=False)
            bin_spk = self.spikes.binned_spikes
        else:
        
            ext_ev0 = {}
            ext_ev1 = {}
            for tr in ev0_dict.keys():
                ext_ev0[tr] = ev0_dict[tr] - self.behav.pre_trial_dur
                ext_ev1[tr] = ev1_dict[tr] + self.behav.post_trial_dur
            tt_start = dict_to_vec(ext_ev0)
            tt_stop = dict_to_vec(ext_ev1)
            time_dict = self.spikes.bin_spikes(self.behav.time_stamps, t_start=tt_start, t_stop=tt_stop, select=self.filter)
            DT = time_dict[list(time_dict.keys())[0]][1] - time_dict[list(time_dict.keys())[0]][0]

            sm_spikes = np.zeros((self.spikes.binned_spikes.shape[0], tr_sel.shape[0]), dtype=object)
            for idxtr in range(tr_sel.shape[0]):
                #tr = tr_sel[idxtr]
                for un in range(self.spikes.binned_spikes.shape[0]):
                    sm_spikes[un, idxtr] = np.convolve(self.spikes.binned_spikes[un, idxtr] / DT, filt_window, mode='same')

            # use the proper binning in ms
            bin_list = self.spikes.bin_spikes(bin_ts, t_start=ev0_dict, t_stop=ev1_dict, select=self.filter,cutFirstLastTP=False)

            # interp to the right size
            bin_spk = np.zeros(sm_spikes.shape, dtype=object)
            for idxtr in range(tr_sel.shape[0]):
                tr = tr_sel[idxtr]
                for un in range(self.spikes.binned_spikes.shape[0]):
                    interp = interp1d(time_dict[tr], sm_spikes[un,idxtr])
                    bin_spk[un, idxtr] = interp(bin_list[tr])

        self.preProcessed = emptyStruct()
        self.preProcessed.numTrials = tr_sel.shape[0]
        self.preProcessed.ydim = self.spikes.binned_spikes.shape[0]

        # create a container for the behav correlates
        tw_correlates = {}
        for var in self.behav.continuous.__dict__.keys():
            tw_correlates[var] = np.zeros((tr_sel.shape[0],), dtype=object)

        tw_correlates['t_ptb'] = np.zeros((tr_sel.shape[0],), dtype=object)

        data = []
        cc = 0
        for tr in tr_sel:
            T = bin_spk[0, cc].shape[0]
            tmp = np.zeros((self.preProcessed.ydim, T))
            for un in range(self.preProcessed.ydim):
                tmp[un, :] = bin_spk[un, cc]
            data += [{'Y': deepcopy(tmp)}]

            # interp variables
            for var in self.behav.continuous.__dict__.keys():
                if ('_fly' in var) or ('hand' in  var):
                    continue
                time_pts = self.behav.time_stamps[tr]
                try:
                    y_val = self.behav.continuous.__dict__[var][tr]
                    non_nan = ~np.isnan(y_val)
                    intrp = interp1d(time_pts[non_nan], y_val[non_nan], bounds_error=False)

                    tw_correlates[var][cc] = intrp(bin_list[tr_sel[cc]])
                except:
                    continue

            for var in self.behav.events.__dict__.keys():
                if var != 't_ptb':
                    continue
                time_pts = self.behav.time_stamps[tr]
                ts = self.behav.events.__dict__[var][tr][0]
                if np.isnan(ts):
                    tw_correlates[var][cc] = np.zeros(bin_list[tr_sel[cc]].shape[0])
                else:
                    tw_correlates[var][cc] = np.zeros(bin_list[tr_sel[cc]].shape[0])
                    ii = (bin_list[tr_sel[cc]] > ts)
                    if any(ii):
                        ii = max(0, np.where(ii)[0][0] - 1)
                        tw_correlates[var][cc][ii] = 1


            cc += 1


        self.preProcessed.data = data
        self.preProcessed.binSize = binMs
        self.preProcessed.trialDur = None
        self.preProcessed.T = []
        for key in bin_list.keys():
            self.preProcessed.T.append(bin_list[key])
        self.preProcessed.covariates = tw_correlates
        self.preprocessing_type = 'P-GPFA'
        self.preProcessed.trialId = tr_sel
        if printEndString:
            print('Preprocessing for P-GPFA completed')
        return

    def preProcPCA(self, binMs=20, init_event='t_flyON', final_event='t_stop', smooth=False,filt_window=None):
        self.preProcPGPFA(binMs=binMs, init_event=init_event, final_event=final_event,printEndString=False, smooth=smooth,
                          filt_window=filt_window)

        # concatenate all data to make it simpler to use with PCA/FA or similar models
        stackData = []
        trialId = []
        stackedCovariate = {}
        for key in self.preProcessed.covariates.keys():
            stackedCovariate[key] = []
        cc = 0
        for xx in self.preProcessed.data:
            stackData += [xx['Y']]
            trialId += [self.preProcessed.trialId[cc]]*xx['Y'].shape[1]
            for key in self.preProcessed.covariates.keys():
                stackedCovariate[key] += [self.preProcessed.covariates[key][cc]]
            cc += 1
        del xx
        stackData = np.hstack(stackData)
        trialId = np.array(trialId,dtype=int)
        for key in self.preProcessed.covariates.keys():
            stackedCovariate[key] = np.hstack(stackedCovariate[key])

        self.preProcessed = emptyStruct()
        self.preProcessed.numTrials = np.unique(trialId).shape[0]
        self.preProcessed.ydim = self.spikes.binned_spikes.shape[0]
        self.preProcessed.data = stackData
        self.preProcessed.binSize = binMs
        self.preProcessed.trialDur = None
        self.preProcessed.T = None
        self.preProcessed.covariates = stackedCovariate
        self.preprocessing_type = 'PCA'
        self.preProcessed.trialId = trialId

    def preProcGPFA_timeWarp(self, list_timepoints=None, var_list=[]):
        """

        :param list_timepoints: a list containing of tuple of three elements: [(ev0, ev1, T0), (ev1, ev2, T1), ...]
            * $ev_j$ : string, name of first event  (e.g. t_start, t_flyON...)
            * $ev_{j+1}$ : string, name of second event (needs to follow ev0)
            * Tj number of time points in which to bin the interval between $ev_j$ and $ev_{j+1}$
            note that the last event of an interval must coincide with the first event of the following interval
        :param var_list: list of stringss, variable names to be time warped
        :return:
        """
        tp_matrix, rate_tensor, sm_traj, raw_traj, fly_pos, tw_correlates, trialId =\
            self.GPFA_YU_preprocessing(list_timepoints=list_timepoints, var_list=var_list)

        trialKeep = ~np.isnan(rate_tensor.sum(axis=(1,2)))
        self.preProcessed = emptyStruct()
        self.preProcessed.data = rate_tensor[trialKeep]
        self.preProcessed.covariates = {}
        for var in tw_correlates.keys():
            self.preProcessed.covariates[var] = tw_correlates[var][trialKeep]

        trialId = trialId[trialKeep]
        self.preProcessed.ydim = rate_tensor.shape[1]
        self.preProcessed.numTrials = np.unique(trialId).shape[0]
        self.preProcessed.binSize = None
        self.preProcessed.trialDur = None
        self.preProcessed.T = tp_matrix[trialKeep]
        self.preProcessed.sm_trajectory = sm_traj[trialKeep]
        self.preProcessed.raw_trajecory = raw_traj[trialKeep]
        self.preprocessing_type = 'PCA'
        self.preProcessed.trialId = trialId
        self.preProcessed.fly_pos = fly_pos[trialKeep]
        self.preProcessed.descr_data = \
        """
        Description of the variable structure:
             \t*) self.preProcessed.data : (# trial x # units x # time points) tensor of firing rate in Hz x time interval
             \t*) self.preProcessed.T : (# trial x # time points), centers of each time interval in seconds
             \t*) self.preProcessed.raw_trajectory : (# trial x 2 x # time points), raw x,y trajectory of the monkey on the sceen in cm
             \t*) self.preProcessed.raw_trajectory : same as above but smooth
             \t*) self.preProcessed.covariates : dictionary, keys are the task variable names, values:
             \t\t (# trials x # time points) time warped task variable
        """
        print('Finished preprocessing for GPFA Byron YU code with time warping')


    def preProcPCA_timeWarp(self, list_timepoints=None, var_list=[],pcaPrep=True, smooth=True,
                            sqrtIfPCA=True, filt_window=None):
        """

        :param list_timepoints: a list containing of tuple of three elements: [(ev0, ev1, T0), (ev1, ev2, T1), ...]
            * $ev_j$ : string, name of first event  (e.g. t_start, t_flyON...)
            * $ev_{j+1}$ : string, name of second event (needs to follow ev0)
            * Tj number of time points in which to bin the interval between $ev_j$ and $ev_{j+1}$
            note that the last event of an interval must coincide with the first event of the following interval
        :param var_list: list of stringss, variable names to be time warped
        :return:
        """
        tp_matrix, rate_tensor, sm_traj, raw_traj, fly_pos, tw_correlates, trialId =\
            self.GPFA_YU_preprocessing(list_timepoints=list_timepoints, var_list=var_list,
                                       pcaPrep=pcaPrep, sqrtIfPCA=sqrtIfPCA, filt_window=filt_window,
                                       smooth=smooth)

        trialKeep = ~np.isnan(rate_tensor.sum(axis=(1,2)))
        self.preProcessed = emptyStruct()
        rate_tensor = rate_tensor[trialKeep]

        # create a rate matrix (# units x # time points stacked)
        trialId = np.repeat(trialId, rate_tensor.shape[2])
        rate_tensor = rate_tensor.transpose((1, 0, 2))
        rate_tensor = rate_tensor.reshape(rate_tensor.shape[0], -1)

        self.preProcessed.data = rate_tensor
        self.preProcessed.covariates = {}
        for var in tw_correlates.keys():
            self.preProcessed.covariates[var] = tw_correlates[var][trialKeep]

        # trialId = trialId[trialKeep]
        self.preProcessed.ydim = rate_tensor.shape[0]
        self.preProcessed.numTrials = np.unique(trialId).shape[0]
        self.preProcessed.binSize = None
        self.preProcessed.trialDur = None
        self.preProcessed.T = tp_matrix[trialKeep]
        self.preProcessed.sm_trajectory = sm_traj[trialKeep]
        self.preProcessed.raw_trajecory = raw_traj[trialKeep]
        self.preprocessing_type = 'PCA'
        self.preProcessed.trialId = trialId
        self.preProcessed.fly_pos = fly_pos[trialKeep]
        self.preProcessed.descr_data = \
        """
        Description of the variable structure:
             \t*) self.preProcessed.data : (# trial x # units x # time points) tensor of firing rate in Hz x time interval
             \t*) self.preProcessed.T : (# trial x # time points), centers of each time interval in seconds
             \t*) self.preProcessed.raw_trajectory : (# trial x 2 x # time points), raw x,y trajectory of the monkey on the sceen in cm
             \t*) self.preProcessed.raw_trajectory : same as above but smooth
             \t*) self.preProcessed.covariates : dictionary, keys are the task variable names, values:
             \t\t (# trials x # time points) time warped task variable
        """
        print('Finished preprocessing for PCA with time warping')


    def preProcGPFA(self, binMs=20, init_event='t_flyON', final_event='t_stop'):
        """

        :param list_timepoints: a list containing of tuple of three elements: [(ev0, ev1, T0), (ev1, ev2, T1), ...]
            * $ev_j$ : string, name of first event  (e.g. t_start, t_flyON...)
            * $ev_{j+1}$ : string, name of second event (needs to follow ev0)
            * Tj number of time points in which to bin the interval between $ev_j$ and $ev_{j+1}$
            note that the last event of an interval must coincide with the first event of the following interval
        :param var_list: list of stringss, variable names to be time warped
        :return:
        """

        var_list = list(self.behav.continuous.__dict__.keys())
        if 'x_fly' in var_list:
            var_list.remove('x_fly')
            var_list.remove('y_fly')
        # get initial event dict
        if init_event == 't_flyON':
            ev0_dict = {}
            for tr in self.behav.events.t_flyOFF.keys():
                ev0_dict[tr] = self.behav.events.t_flyOFF[tr] - self.behav.flyON_dur
        else:
            try:
                ev0_dict = self.behav.events.__dict__[init_event]
            except KeyError:
                raise KeyError('Event "%s" was not loaded' % init_event)

        # get final event dict
        try:
            ev1_dict = self.behav.events.__dict__[final_event]
        except KeyError:
            raise KeyError('Event "%s" was not loaded' % final_event)


        #GPFA_YU_preprocessing_noTW(self, t_start, t_stop, var_list=[],binwidth_ms=20)
        tp_matrix, rate_tensor, sm_traj, raw_traj, fly_pos, tw_correlates, trialId =\
            self.GPFA_YU_preprocessing_noTW(ev0_dict, ev1_dict, var_list=var_list, binwidth_ms=binMs)

        self.preProcessed = emptyStruct()
        self.preProcessed.data = rate_tensor#[trialKeep]
        self.preProcessed.covariates = {}
        for var in tw_correlates.keys():
            self.preProcessed.covariates[var] = tw_correlates[var]#[trialKeep]

        trialId = trialId#[trialKeep]
        self.preProcessed.ydim = rate_tensor[0].shape[0]
        self.preProcessed.numTrials = len(rate_tensor.keys())
        self.preProcessed.binSize = None
        self.preProcessed.trialDur = None
        self.preProcessed.T = tp_matrix
        self.preProcessed.sm_trajectory = sm_traj
        self.preProcessed.raw_trajecory = raw_traj
        self.preprocessing_type = 'PCA'
        self.preProcessed.trialId = trialId
        self.preProcessed.fly_pos = fly_pos
        self.preProcessed.descr_data = \
        """
        Description of the variable structure:
             \t*) self.preProcessed.data :  dictionary containing (# units x # time points) tensor of spike counts, one matrix per trial
             \t*) self.preProcessed.T : dictionary containing (# time points)
             \t*) self.preProcessed.raw_trajectory : (# trial x 2 x # time points), raw x,y trajectory of the monkey on the sceen in cm
             \t*) self.preProcessed.raw_trajectory : same as above but smooth
             \t*) self.preProcessed.covariates : dictionary, keys are the task variable names, values:
             \t\t (# trials x # time points) time warped task variable
        """
        print('Finished preprocessing for GPFA Byron YU code with time warping')


    def time_stamps_rebin(self, binwidth_ms=20, t0_vec=None):
        rebin = {}
        for tr in self.behav.time_stamps.keys():
            ts = self.behav.time_stamps[tr]
            if t0_vec is None:
                tp_num = np.floor((ts[-1] - ts[0]) * 1000 / (binwidth_ms))
                rebin[tr] = ts[0] + np.arange(tp_num) * binwidth_ms / 1000.
            else:
                tp_num = np.floor((ts[-1] - t0_vec[tr]) * 1000 / (binwidth_ms))
                rebin[tr] = t0_vec[tr] + np.arange(tp_num) * binwidth_ms / 1000.

        return rebin

if __name__ == '__main__':
    import matplotlib.pylab as plt
    from sklearn.decomposition import PCA

    # create a gauss window for smoothing
    filtwidth = 10
    t = np.linspace(-2 * filtwidth, 2 * filtwidth, 4 * filtwidth + 1)
    h = np.exp(-t ** 2 / (2 * filtwidth ** 2))
    h = h - h[0]
    h = h / np.sum(h)

    filePath = '/Volumes/WD_Edo/firefly_analysis/LFP_band/DATASET_accel/m53s113.mat'

    # load data
    dat = fireFly_dataPreproc(filePath)
    # set up filter for init cond
    dat.setInitialCond(condition='noMovement', init_event='t_flyON')

    dat.preProcGPFA(binMs=50, init_event='t_flyON', final_event='t_stop')
    prepGPFA = deepcopy(dat.preProcessed)

    dat.preProcPCA(binMs=50, init_event ='t_flyON',final_event = 't_stop',smooth=True, filt_window=h)

    preprocPCA_sm = deepcopy(dat.preProcessed.data)

    dat.preProcPCA(binMs=50, init_event ='t_flyON',final_event = 't_stop',smooth=False, filt_window=h)

    preprocPCA = deepcopy(dat.preProcessed.data)
    trialId_PCA = deepcopy(dat.preProcessed.trialId)

    dat.preProcPGPFA(binMs=50, init_event='t_flyON', final_event='t_stop')

    preprocPGPFA = deepcopy(dat.preProcessed.data)
    trialId_PGPFA = deepcopy(dat.preProcessed.trialId)

    idxtr = 60
    plt.figure(figsize=(10,4))
    tr = trialId_PGPFA[idxtr]
    un = 46
    plt.subplot(131)
    plt.title('PCA raw')
    sel = trialId_PCA == tr
    plt.plot(preprocPCA[un,sel])

    plt.subplot(132)
    plt.title('PCA smooth')
    sel = trialId_PCA == tr
    plt.plot(preprocPCA_sm[un, sel])

    plt.subplot(133)
    plt.title('PGPFA')
    sel = np.where(trialId_PGPFA == tr)[0][0]
    plt.plot(preprocPGPFA[sel]['Y'][un])


    # time warping check
    dat.preProcGPFA_timeWarp(list_timepoints=[('t_flyON', 't_stop', 50)],
                              var_list=['rad_vel','ang_vel','rad_target','ang_target'])

    preprocGPFA_TW = deepcopy(dat.preProcessed.data)

    dat.preProcPCA_timeWarp(list_timepoints=[('t_flyON', 't_stop', 50)],
                              var_list=['rad_vel', 'ang_vel', 'rad_target', 'ang_target'],
                              pcaPrep=True, sqrtIfPCA=False, filt_window=h,smooth=True)

    preprocPCA_tw_sm = deepcopy(dat.preProcessed.data)
    dat.preProcPCA_timeWarp(list_timepoints=[('t_flyON', 't_stop', 50)],
                             var_list=['rad_vel', 'ang_vel', 'rad_target', 'ang_target'],
                             pcaPrep=True, sqrtIfPCA=False, filt_window=h,smooth=False)

    preprocPCA_tw = deepcopy(dat.preProcessed.data)

    plt.figure(figsize=(10, 4))
    tr = trialId_PGPFA[idxtr]
    un = 46

    plt.subplot(141)
    plt.title('PCA raw')
    sel = dat.preProcessed.trialId == tr
    plt.plot(preprocPCA_tw[un, sel])

    plt.subplot(142)
    plt.title('PCA smooth')
    sel = dat.preProcessed.trialId == tr
    plt.plot(preprocPCA_tw_sm[un, sel])

    plt.subplot(143)
    plt.title('GPFA')
    plt.plot(preprocGPFA_TW[idxtr,un])

    plt.subplot(144)
    plt.title('GPFA no TW')
    plt.plot(prepGPFA.data[idxtr][un,:])


    #
    # plt.figure()
    # iid = dat.preProcessed.trialId == 121
    # plt.plot(smRate[46, iid])
    # plt.plot(rowRate[46, iid])



    # trind = 121
    # unt = 46
    # plt.subplot(121)
    # plt.plot(dat.preProcessed.covariates['rad_vel'][trind] / 200)
    # plt.plot(dat.preProcessed.data[trind]['Y'][unt, :])
    #
    # plt.subplot(122)
    # ts = dat.behav.time_stamps[dat.preProcessed.trialId[trind]]
    # i0 = np.where(ts < dat.behav.events.t_flyOFF[dat.preProcessed.trialId[trind]] - 0.3)[0][-1]
    # i1 = np.where(ts < dat.behav.events.t_stop[dat.preProcessed.trialId[trind]])[0][-1]
    # plt.plot(dat.behav.continuous.rad_vel[dat.preProcessed.trialId[trind]][i0:i1]/200)
    # spktim = dat.spikes.spike_times[unt,dat.preProcessed.trialId[trind]]
    # spktim = spktim[(spktim >= ts[i0]) & (spktim <= ts[i1])]
    # plt.vlines(spktim/0.006,0,1,color='r')


    ## FIT PCA AND PLOT
    # model = PCA(2)
    # brain_area = 'PPC'
    # res_pca = model.fit(np.sqrt(preprocPCA.data[dat.spikes.brain_area==brain_area,:].T))
    # trans = res_pca.transform(np.sqrt(preprocPCA.data[dat.spikes.brain_area==brain_area,:]).T)
    #
    # plt.figure(figsize=(10,8))
    #     # ax1 = plt.subplot(221)
    #     # ax2 = plt.subplot(222)
    #     #
    #     # ax3 = plt.subplot(223)
    #     # ax4 = plt.subplot(224)
    #
    # centers = [[200,-80], [200,0], [200,80]]
    # # std_mat = {0:np.zeros((0,15)), 1:np.zeros((0,15)), 2:np.zeros((0,15))}
    # interp_mat = {0:np.zeros((0,15)), 1:np.zeros((0,15)), 2:np.zeros((0,15))}
    # interp_mat2 = {0:np.zeros((0,15)), 1:np.zeros((0,15)), 2:np.zeros((0,15))}
    #
    # for tr in range(np.unique(preprocPCA.trialId).shape[0]):
    #     sel = preprocPCA.trialId == np.unique(preprocPCA.trialId)[tr]
    #
    #     rad_targ = preprocPCA.covariates['rad_target'][sel][0]
    #     ang_targ = preprocPCA.covariates['ang_target'][sel][0]
    #     x_targ = np.cos(ang_targ/360. * np.pi * 2) * rad_targ
    #     y_targ = np.sin(ang_targ/360. * np.pi * 2) * rad_targ
    #
    #
    #     print(x_targ,y_targ)
    #     if np.linalg.norm(np.array(centers[0])-[x_targ,y_targ]) < 20:
    #         color = 'r'
    #         xx = np.arange(sel.sum())
    #         ts = np.linspace(0, xx[-1], 15)
    #         interp = interp1d(range(sel.sum()), trans[sel, 0])
    #         interp_mat[0] = np.vstack([interp_mat[0], interp(ts).reshape(1,15)])
    #
    #         interp = interp1d(range(sel.sum()), trans[sel, 1])
    #         interp_mat2[0] = np.vstack([interp_mat2[0], interp(ts).reshape(1,15)])
    #
    #
    #     elif np.linalg.norm(np.array(centers[1])-[x_targ,y_targ]) < 20:
    #         color = 'b'
    #         xx = np.arange(sel.sum())
    #         ts = np.linspace(0, xx[-1], 15)
    #         interp = interp1d(range(sel.sum()), trans[sel, 0])
    #         interp_mat[1] = np.vstack([interp_mat[1], interp(ts).reshape(1, 15)])
    #
    #         interp = interp1d(range(sel.sum()), trans[sel, 1])
    #         interp_mat2[1] = np.vstack([interp_mat2[1], interp(ts).reshape(1, 15)])
    #
    #     elif np.linalg.norm(np.array(centers[2]) - [x_targ, y_targ]) < 20:
    #         xx = np.arange(sel.sum())
    #         ts = np.linspace(0, xx[-1], 15)
    #         interp = interp1d(range(sel.sum()), trans[sel, 0])
    #         interp_mat[2] = np.vstack([interp_mat[2], interp(ts).reshape(1, 15)])
    #
    #         interp = interp1d(range(sel.sum()), trans[sel, 1])
    #         interp_mat2[2] = np.vstack([interp_mat2[2], interp(ts).reshape(1, 15)])
    #
    #         color = 'g'
    #     else:
    #         continue
    #
    #     ax1.plot(np.linspace(0,1,sel.sum()),trans[sel, 0],color=color)
    #     ax2.plot(np.linspace(0,1,sel.sum()),trans[sel, 1],color=color)
    #
    # ax3.plot(np.linspace(0,1,15), interp_mat[0].mean(axis=0),color='r')
    # ax3.plot(np.linspace(0,1,15), interp_mat[1].mean(axis=0),color='b')
    # ax3.plot(np.linspace(0,1,15), interp_mat[2].mean(axis=0),color='g')
    #
    # ax3.fill_between(np.linspace(0, 1, 15),
    #                  interp_mat[0].mean(axis=0) + interp_mat[0].std(axis=0),
    #                  interp_mat[0].mean(axis=0) - interp_mat[0].std(axis=0), color='r', alpha=0.5)
    # ax3.fill_between(np.linspace(0, 1, 15),
    #                  interp_mat[1].mean(axis=0) - interp_mat[1].std(axis=0),
    #                  interp_mat[1].mean(axis=0) + interp_mat[1].std(axis=0), color='b',
    #                  alpha=0.5)
    # ax3.fill_between(np.linspace(0, 1, 15),
    #                  interp_mat[2].mean(axis=0) - interp_mat[2].std(axis=0),
    #                  interp_mat[2].mean(axis=0) + interp_mat[2].std(axis=0), color='g',
    #                  alpha=0.5)
    #
    #
    # ax4.plot(np.linspace(0, 1, 15), interp_mat2[0].mean(axis=0), color='r')
    # ax4.plot(np.linspace(0, 1, 15), interp_mat2[1].mean(axis=0), color='b')
    # ax4.plot(np.linspace(0, 1, 15), interp_mat2[2].mean(axis=0), color='g')
    #
    # ax4.fill_between(np.linspace(0, 1, 15),
    #                  interp_mat2[0].mean(axis=0) + interp_mat2[0].std(axis=0),
    #                  interp_mat2[0].mean(axis=0) - interp_mat2[0].std(axis=0), color='r', alpha=0.5)
    # ax4.fill_between(np.linspace(0, 1, 15),
    #                  interp_mat2[1].mean(axis=0) - interp_mat2[1].std(axis=0),
    #                  interp_mat2[1].mean(axis=0) + interp_mat2[1].std(axis=0), color='b',
    #                  alpha=0.5)
    # ax4.fill_between(np.linspace(0, 1, 15),
    #                  interp_mat2[2].mean(axis=0) - interp_mat2[2].std(axis=0),
    #                  interp_mat2[2].mean(axis=0) + interp_mat2[2].std(axis=0), color='g',
    #                  alpha=0.5)
    #
    #
